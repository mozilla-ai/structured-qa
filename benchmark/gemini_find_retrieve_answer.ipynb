{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RKWbX7BHEgr"
      },
      "source": [
        "# Structured Q&A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYuloevCHEgu"
      },
      "source": [
        "Source code: https://github.com/mozilla-ai/structured-qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgYAsUQWHEgv"
      },
      "source": [
        "Docs: https://mozilla-ai.github.io/structured-qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbFAX4heHEgv"
      },
      "source": [
        "## Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2HoyF-xbHEgv",
        "outputId": "ba13b9dc-18c6-4ed1-f82b-8a8a71445bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/mozilla-ai/structured-qa.git@5-add-benchmark\n",
            "  Cloning https://github.com/mozilla-ai/structured-qa.git (to revision 5-add-benchmark) to /tmp/pip-req-build-kwo0xd9n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mozilla-ai/structured-qa.git /tmp/pip-req-build-kwo0xd9n\n",
            "  Running command git checkout -b 5-add-benchmark --track origin/5-add-benchmark\n",
            "  Switched to a new branch '5-add-benchmark'\n",
            "  Branch '5-add-benchmark' set up to track remote branch '5-add-benchmark' from 'origin'.\n",
            "  Resolved https://github.com/mozilla-ai/structured-qa.git to commit 82f37f304be63e8096b40317eace08ff70ff0891\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (0.7.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (0.27.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (0.7.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (2.10.6)\n",
            "Requirement already satisfied: pymupdf4llm in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (0.0.17)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (6.0.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (3.12.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (from structured-qa==0.3.3.dev108+g82f37f3) (1.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->structured-qa==0.3.3.dev108+g82f37f3) (2.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->structured-qa==0.3.3.dev108+g82f37f3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->structured-qa==0.3.3.dev108+g82f37f3) (2.27.2)\n",
            "Requirement already satisfied: pymupdf>=1.24.10 in /usr/local/lib/python3.11/dist-packages (from pymupdf4llm->structured-qa==0.3.3.dev108+g82f37f3) (1.25.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (1.26.4)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->structured-qa==0.3.3.dev108+g82f37f3) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (1.24.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->structured-qa==0.3.3.dev108+g82f37f3) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit->structured-qa==0.3.3.dev108+g82f37f3) (1.17.0)\n",
            "Building wheels for collected packages: structured-qa\n",
            "  Building wheel for structured-qa (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for structured-qa: filename=structured_qa-0.3.3.dev108+g82f37f3-py3-none-any.whl size=13250 sha256=6563d68f35d99a2e5f1a8b9e0bff9eceae7a72c27b99dba8e6188901f5c1352b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-09itl4q3/wheels/be/a2/66/5bd06ba07afee632d178971d710ae5150fe6379c43e361cd32\n",
            "Successfully built structured-qa\n",
            "Installing collected packages: structured-qa\n",
            "  Attempting uninstall: structured-qa\n",
            "    Found existing installation: structured-qa 0.3.3.dev107+g4ea56e2\n",
            "    Uninstalling structured-qa-0.3.3.dev107+g4ea56e2:\n",
            "      Successfully uninstalled structured-qa-0.3.3.dev107+g4ea56e2\n",
            "Successfully installed structured-qa-0.3.3.dev108+g82f37f3\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/mozilla-ai/structured-qa.git@5-add-benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p_hsSGafHEgw",
        "outputId": "978e3aa8-8a08-46dd-b573-1fe9136aa4df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 16:58:08--  https://raw.githubusercontent.com/mozilla-ai/structured-qa/refs/heads/5-add-benchmark/benchmark/structured_qa.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21441 (21K) [text/plain]\n",
            "Saving to: ‘structured_qa.csv.1’\n",
            "\n",
            "\rstructured_qa.csv.1   0%[                    ]       0  --.-KB/s               \rstructured_qa.csv.1 100%[===================>]  20.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 16:58:08 (122 MB/s) - ‘structured_qa.csv.1’ saved [21441/21441]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mozilla-ai/structured-qa/refs/heads/5-add-benchmark/benchmark/structured_qa.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MDfM6cyHEgx"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5bLJE4U7HEgx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab.userdata import get, SecretNotFoundError\n",
        "\n",
        "try:\n",
        "    genai.configure(api_key=get(\"GOOGLE_API_KEY\"))\n",
        "except SecretNotFoundError as e:\n",
        "    raise RuntimeError(\"Please set the GOOGLE_API_KEY secret to your API key\") from e\n",
        "os.environ[\"LOGURU_LEVEL\"] = \"INFO\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y3yUsRDWHEgy"
      },
      "outputs": [],
      "source": [
        "from loguru import logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgpODLeJHEgy"
      },
      "source": [
        "## Function to Process a single Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n6d8F7cYHEgy"
      },
      "outputs": [],
      "source": [
        "from structured_qa.config import FIND_PROMPT\n",
        "from structured_qa.preprocessing import document_to_sections_dir\n",
        "from structured_qa.workflow import find_retrieve_answer\n",
        "\n",
        "\n",
        "\n",
        "ANSWER_WITH_TYPE_PROMPT = \"\"\"\n",
        "You are a rigorous assistant answering questions.\n",
        "You must only answer based on the current information available which is:\n",
        "\n",
        "```\n",
        "{CURRENT_INFO}\n",
        "```\n",
        "\n",
        "If the current information available not enough to answer the question,\n",
        "you must return \"I need more info\" srting and nothing else:\n",
        "\n",
        "If the current information is enough to answer, you must return one of the following formats:\n",
        "- YES/NO (for boolean questions)\n",
        "- Number (for numeric questions)\n",
        "- Single letter (for multiple-choice questions)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def process_document(\n",
        "    document_file,\n",
        "    document_data,\n",
        "    model,\n",
        "    find_prompt: str = FIND_PROMPT,\n",
        "    answer_prompt: str = ANSWER_WITH_TYPE_PROMPT,\n",
        "):\n",
        "    sections_dir = Path(\"sections\") / Path(document_file).stem\n",
        "    if not sections_dir.exists():\n",
        "        logger.info(\"Splitting document into sections\")\n",
        "        document_to_sections_dir(document_file, sections_dir)\n",
        "\n",
        "    logger.info(\"Predicting\")\n",
        "    answers = {}\n",
        "    sections = {}\n",
        "    for index, row in document_data.iterrows():\n",
        "        question = row[\"question\"]\n",
        "        logger.info(f\"Question: {question}\")\n",
        "        answer, sections_checked = find_retrieve_answer(\n",
        "            question, model, sections_dir, find_prompt, answer_prompt\n",
        "        )\n",
        "        logger.info(f\"Answer: {answer}\")\n",
        "        answers[index] = answer\n",
        "        sections[index] = sections_checked[-1] if sections_checked else None\n",
        "\n",
        "    return answers, sections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdlWjANdHEgz"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9zx8nCaZHEgz"
      },
      "outputs": [],
      "source": [
        "from structured_qa.model_loaders import load_gemini_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U4R84hHRHEgz"
      },
      "outputs": [],
      "source": [
        "model = load_gemini_model(\"gemini-2.0-flash-exp\", system_prompt=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEzqJJ1yHEgz"
      },
      "source": [
        "# Run Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-qtPf9RmHEgz",
        "outputId": "4930db62-5bc8-46ab-c51a-c4eca0ecd0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-02-03 16:58:11.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoading input data\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:11.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mDownloading document https://aiindex.stanford.edu/wp-content/uploads/2024/05/HAI_AI-Index-Report-2024.pdf\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:11.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mFile HAI_AI-Index-Report-2024.pdf.pdf already exists\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:11.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPredicting\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:11.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: which type of risk was identified as the leading concern globally? -A: Fairness risks. -B: Privacy and data governance risks. -C: Risks related to generative AI deployment.\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:11.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 0\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:19.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:20.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:22.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:24.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:24.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: In which geographical area were fairness risks selected by the smallest percentage of respondents? -A: Asia. -B: Europe. -C: North America.\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:24.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:26.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:28.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: C\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:28.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What is a major consequence of the rising training costs for foundation models? -A: The exclusion of universities from developing leading-edge foundation models. -B: Increased collaboration between universities and AI companies. -C: A decrease in the number of policy initiatives related to AI research.\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:28.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:29.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:31.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:32.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 16:58:32.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:36.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:38.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:39.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:41.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:42.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:45.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:46.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:48.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: A\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:48.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How the AI Index and Epoch AI estimated training costs for foundation models? -A: By surveying AI companies on their reported expenses. -B: By analyzing government funding allocated to AI research. -C: By analyzing training duration, hardware type, quantity, and utilization rate.\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:48.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 16:59:48.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:00:49.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:00:51.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:00:52.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:00:56.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:00:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:00.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: C\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:00.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What is a major source of inequality in AI related to tokenization? -A: The significant variability in the number of tokens required to represent the same content across different languages. -B: The uniform processing speed of all languages. -C: The consistent cost of inference across different languages.\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:00.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:03.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:06.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: A\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:06.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What are the three major inequalities resulting from variable tokenization? -A: Increased model training costs, limited access to resources, and biased results. -B: Higher inference costs, longer processing times, and reduced available context for the model. -C:  Limited language support, increased hardware requirements, and data bias.\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:06.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:08.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:01:08.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:09.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:09.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many AI-related regulations were enacted in the United States in 2023?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:09.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:11.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:13.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 25\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:13.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Which of the following was identified as a high relevance AI regulation? -A: Securities and Exchange Commission’s Cybersecurity Risk Management Strategy. -B: Copyright Office and Library of Congress’ Copyright Registration Guidance. -C: Regulations related to foreign trade and international finance\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:13.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:14.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:17.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:17.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Which country had the highest proportion of female bachelor's graduates in informatics, computer science, computer engineering, and information technology among the surveyed European nations? -A: France. -B: Bulgaria. -C: United Kingdom\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:17.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:18.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:19.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:22.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:23.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:02:23.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:24.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:28.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:30.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:32.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:33.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:35.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:35.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Which countries reported the smallest proportion of female master's graduates in informatics, CS, CE, and IT as of 2022? -A: Estonia, Romania, and Bulgaria. -B: United Kingdom, Germany, and Switzerland. -C: Belgium, Italy, and Switzerland.\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:35.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:37.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:38.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:39.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:03:39.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:41.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:42.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:44.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:46.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:48.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:49.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:51.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:53.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: C\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mDownloading document https://arxiv.org/pdf/1706.03762\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mFile 1706.03762.pdf already exists\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPredicting\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What type of architecture does the model use? -A: decoder only -B: encoder only -C: encoder-decoder\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:04:55.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:05:56.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:05:58.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: C\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:05:58.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many layers compose the encoder?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:05:58.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:04.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:06.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 6\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:06.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many layers compose the decoder?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:06.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:07.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:09.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 6\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:09.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many parallel attention heads are used?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:09.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:12.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:13.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 8\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:13.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Does the final model use learned embeddings for the input and output tokens?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:13.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:15.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:06:15.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:16.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: YES\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:16.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Does the final model use learned positional embeddings?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:16.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:17.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:19.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: NO\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:19.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many GPUs were used for training?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:19.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:20.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:21.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 8\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:21.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What type of GPUs were used for training? -A: NVIDIA A100 -B: NVIDIA P100 -C: NVIDIA T4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:21.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:23.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:24.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:24.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What optimizer was used for training? -A: AdamW -B: Adam -C: SGD\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:24.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:25.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:27.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:27.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many warmup steps were used?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:27.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:07:27.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:28.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:29.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 4000\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:29.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What was the dropout rate used for the base model?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:29.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:31.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:32.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 0.1\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:32.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mDownloading document https://arxiv.org/pdf/2106.09685.pdf\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:32.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mFile 2106.09685.pdf.pdf already exists\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:32.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPredicting\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:32.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Does LoRA work with any neural network containing dense layers?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:32.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:34.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:35.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:37.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:38.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:39.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:08:39.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:42.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: YES\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:42.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: By how much can LoRA reduce GPU memory requirements during training? -A: 10x, -B: 5x, -C: 3x\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:42.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:43.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:45.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:47.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:49.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:54.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:55.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:57.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:58.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: C\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:58.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: In billions, how many trainable parameters does GPT-3 have?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:58.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:09:58.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:00.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:01.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:03.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:04.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 175\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:04.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Does LoRA introduce additional inference latency compared to full fine-tuning?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:04.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:06.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:07.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:09.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:10.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:13.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:11:13.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:15.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:17.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:18.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:20.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:21.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:22.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:24.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: NO\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:24.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mDownloading document https://arxiv.org/pdf/2201.11903\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:24.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mFile 2201.11903.pdf already exists\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:24.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPredicting\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:24.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Is Arithmetic reasoning is a task that language models often find very easy?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:24.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:25.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:27.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: NO\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:27.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many large language models were evaluated?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:27.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:12:27.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:28.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:42.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 5\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:42.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many benchmarks were used to evaluate arithmetic reasoning?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:42.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:47.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:52.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 5\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:52.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Is symbolic reasoning usually simple for humans but challenging for language models?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:52.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:54.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:56.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: YES\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:56.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many words have the example names that the model has seen for letter concatenation? -A: 3 -B: 2 -C: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:56.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:59.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:59.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Which symbolic reasoning task is used as an out-of-domain evaluation? -A: Coin Flip -B: Tower of Hanoi -C: Chess puzzles\u001b[0m\n",
            "\u001b[32m2025-02-03 17:13:59.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:14:00.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:14:00.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:13.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: A\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:13.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many annotators provided independent chains of thought?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:13.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:16.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:23.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 2\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:23.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many random samples were examined to understand model performance?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:23.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:29.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:35.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:36.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:39.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:41.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:43.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:15:43.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:05.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 36505.75ms\n",
            "\u001b[32m2025-02-03 17:17:44.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 100\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:44.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mDownloading document https://arxiv.org/pdf/2210.05189\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:44.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mFile 2210.05189.pdf already exists\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:44.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPredicting\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:44.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Can recurrent networks also be converted to decision trees?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:44.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:45.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:47.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: YES\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:47.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many layers are in the toy model (y = x^2)?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:47.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:48.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:50.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:51.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:52.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:54.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:17:54.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1695.42ms\n",
            "\u001b[32m2025-02-03 17:18:57.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:18:58.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:00.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:01.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:03.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:05.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:06.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:08.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:09.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:19:09.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:10.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:12.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:13.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:15.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:16.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:17.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:19.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:21.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:22.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: NOT FOUND\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:22.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: Does the toy model (y = x^2) use Sigmoid activation function?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:22.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:20:22.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:24.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:25.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:27.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:28.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:31.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:32.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:33.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:36.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: NO\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:36.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many parameters are in the toy model (y = x^2) tree?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:36.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:38.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:21:38.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:22:39.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:22:52.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:22:55.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:22:56.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:09.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 14\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:09.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many layers are in the half-moon neural network?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:09.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:11.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:17.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:19.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:22.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:23:22.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:23.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:24.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:26.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:31.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: 3\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:31.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What is the main computational advantage of decision trees? -A: Less storage memory, -B: Fewer operations, -C: Lower accuracy\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:31.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:34.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:35.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:36.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:38.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:39.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:24:39.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:41.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: B\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:41.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mDownloading document https://arxiv.org/pdf/2302.13971\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:41.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mFile 2302.13971.pdf already exists\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:41.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPredicting\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:41.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: What proportion of the pre-training data was from Github? -A: 4.5% -B: 15.0% -C: 4%\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:41.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:42.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:43.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:45.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:46.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:47.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:49.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:51.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:52.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:25:52.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n",
            "\u001b[32m2025-02-03 17:26:53.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 1\u001b[0m\n",
            "\u001b[32m2025-02-03 17:26:55.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 2\u001b[0m\n",
            "\u001b[32m2025-02-03 17:26:56.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 3\u001b[0m\n",
            "\u001b[32m2025-02-03 17:26:58.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 4\u001b[0m\n",
            "\u001b[32m2025-02-03 17:26:59.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 5\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:00.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mAnswer: A\n",
            "\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:00.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_document\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mQuestion: How many languages did the Wikipedia data cover?\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:00.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 6\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:02.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 7\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:03.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 8\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:05.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mCurrent calls: 9\u001b[0m\n",
            "\u001b[32m2025-02-03 17:27:05.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mstructured_qa.model_loaders\u001b[0m:\u001b[36mget_response\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mWaiting for 60 seconds\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-066bcd0600a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {downloaded_document} already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded_document\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-03b0e88e7997>\u001b[0m in \u001b[0;36mprocess_document\u001b[0;34m(document_file, document_data, model, find_prompt, answer_prompt)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Question: {question}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         answer, sections_checked = find_retrieve_answer(\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msections_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/structured_qa/workflow.py\u001b[0m in \u001b[0;36mfind_retrieve_answer\u001b[0;34m(question, model, sections_dir, find_prompt, answer_prompt, max_sections_to_check)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to generate completion: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/structured_qa/model_loaders.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_calls\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for 60 seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "logger.info(\"Loading input data\")\n",
        "data = pd.read_csv(\"structured_qa.csv\")\n",
        "data[\"pred_answer\"] = [None] * len(data)\n",
        "data[\"pred_section\"] = [None] * len(data)\n",
        "\n",
        "for document_link, document_data in data.groupby(\"document\"):\n",
        "    logger.info(f\"Downloading document {document_link}\")\n",
        "    downloaded_document = Path(f\"{Path(document_link).name}.pdf\")\n",
        "    if not Path(downloaded_document).exists():\n",
        "        urlretrieve(document_link, downloaded_document)\n",
        "        logger.info(f\"Downloaded {document_link} to {downloaded_document}\")\n",
        "    else:\n",
        "        logger.info(f\"File {downloaded_document} already exists\")\n",
        "\n",
        "    answers, sections = process_document(downloaded_document, document_data, model)\n",
        "\n",
        "    for index in document_data.index:\n",
        "        data.loc[index, \"pred_answer\"] = str(answers[index]).upper()\n",
        "        data.loc[index, \"pred_section\"] = sections[index]\n",
        "\n",
        "data.to_csv(\"results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eW9TIKjHEgz"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv(\"results.csv\")\n",
        "for index, result in results.iterrows():\n",
        "    results.loc[index, \"pred_answer\"] = result[\"pred_answer\"].strip()\n",
        "    if result[\"pred_answer\"].startswith(\n",
        "        (f\"-{result['answer']}\", f\"{result['answer']}\")\n",
        "    ):\n",
        "        results.loc[index, \"pred_answer\"] = result[\"answer\"]\n",
        "results.loc[results[\"answer\"] != results[\"pred_answer\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhenESELHEgz"
      },
      "outputs": [],
      "source": [
        "accuracy = sum(results[\"answer\"] == results[\"pred_answer\"]) / len(results)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-acmSBPMvo1w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}