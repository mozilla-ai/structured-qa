{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code: https://github.com/mozilla-ai/structured-qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs: https://mozilla-ai.github.io/structured-qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/mozilla-ai/structured-qa.git@5-add-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mozilla-ai/structured-qa/refs/heads/5-add-benchmark/benchmark/structured_qa.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.colab.userdata import get, SecretNotFoundError\n",
    "\n",
    "try:\n",
    "    genai.configure(api_key=get(\"GOOGLE_API_KEY\"))\n",
    "except SecretNotFoundError as e:\n",
    "    raise RuntimeError(\"Please set the GOOGLE_API_KEY secret to your API key\") from e\n",
    "os.environ[\"LOGURU_LEVEL\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Process a single Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from structured_qa.config import FIND_PROMPT\n",
    "from structured_qa.preprocessing import document_to_sections_dir\n",
    "from structured_qa.workflow import find_retrieve_answer\n",
    "\n",
    "\n",
    "ANSWER_WITH_TYPE_PROMPT = \"\"\"\n",
    "You are a rigorous assistant answering questions.\n",
    "You only answer based on the current information available.\n",
    "You should only answer with ANSWER_TYPE.\n",
    "\n",
    "The current information available is:\n",
    "\n",
    "```\n",
    "{CURRENT_INFO}\n",
    "```\n",
    "\n",
    "If the current information available not enough to answer the question,\n",
    "you must return the following message and nothing else:\n",
    "\n",
    "```\n",
    "I need more info.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def process_document(\n",
    "    document_file,\n",
    "    document_data,\n",
    "    model,\n",
    "    find_prompt: str = FIND_PROMPT,\n",
    "    answer_prompt: str = ANSWER_WITH_TYPE_PROMPT,\n",
    "):\n",
    "    sections_dir = Path(\"sections\") / Path(document_file).stem\n",
    "    if not sections_dir.exists():\n",
    "        logger.info(\"Splitting document into sections\")\n",
    "        document_to_sections_dir(document_file, sections_dir)\n",
    "\n",
    "    logger.info(\"Predicting\")\n",
    "    answers = {}\n",
    "    sections = {}\n",
    "    for index, row in document_data.iterrows():\n",
    "        question = row[\"question\"]\n",
    "        try:\n",
    "            float(row[\"answer\"])\n",
    "            answer_type = \"a number\"\n",
    "        except ValueError:\n",
    "            if row[\"answer\"] in (\"YES\", \"NO\"):\n",
    "                answer_type = \"YES or NO\"\n",
    "            else:\n",
    "                answer_type = \"a single letter\"\n",
    "\n",
    "            answer_prompt = answer_prompt.replace(\"ANSWER_TYPE\", answer_type)\n",
    "\n",
    "        logger.info(f\"Question: {question}\")\n",
    "        answer, sections_checked = find_retrieve_answer(\n",
    "            question, model, sections_dir, find_prompt, answer_prompt\n",
    "        )\n",
    "\n",
    "        answers[index] = answer\n",
    "        sections[index] = sections_checked[-1] if sections_checked else None\n",
    "\n",
    "    return answers, sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from structured_qa.model_loaders import load_gemini_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_gemini_model(\n",
    "    \"gemini-2.0-flash-exp\",\n",
    "    system_prompt=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "logger.info(\"Loading input data\")\n",
    "data = pd.read_csv(\"structured_qa.csv\")\n",
    "data[\"pred_answer\"] = [None] * len(data)\n",
    "data[\"pred_section\"] = [None] * len(data)\n",
    "\n",
    "for document_link, document_data in data.groupby(\"document\"):\n",
    "    logger.info(f\"Downloading document {document_link}\")\n",
    "    downloaded_document = Path(f\"{Path(document_link).name}.pdf\")\n",
    "    if not Path(downloaded_document).exists():\n",
    "        urlretrieve(document_link, downloaded_document)\n",
    "        logger.info(f\"Downloaded {document_link} to {downloaded_document}\")\n",
    "    else:\n",
    "        logger.info(f\"File {downloaded_document} already exists\")\n",
    "\n",
    "    answers, sections = process_document(downloaded_document, document_data, model)\n",
    "\n",
    "    for index in document_data.index:\n",
    "        data.loc[index, \"pred_answer\"] = str(answers[index]).upper()\n",
    "        data.loc[index, \"pred_section\"] = sections[index]\n",
    "\n",
    "data.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results.csv\")\n",
    "results.loc[results[\"answer\"] != results[\"pred_answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(results[\"answer\"] == results[\"pred_answer\"]) / len(results)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
