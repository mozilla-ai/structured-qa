{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code: https://github.com/mozilla-ai/structured-qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs: https://mozilla-ai.github.io/structured-qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to `Edit`â†’`Notebook Settings`\n",
    "- Select T4 GPU from the Hardware Accelerator section\n",
    "- Click `Save` and accept.\n",
    "\n",
    "Next, we'll confirm that we can connect to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"GPU not available\")\n",
    "else:\n",
    "    print(\"GPU is available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ragatouille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/mozilla-ai/structured-qa.git@5-add-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mozilla-ai/structured-qa/refs/heads/5-add-benchmark/benchmark/structured_qa.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "GEMINI_API_KEY = None\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Please set the GEMINI_API_KEY variable to your API key\")\n",
    "os.environ[\"LOGURU_LEVEL\"] = \"INFO\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def load_pdf(pdf_file: str) -> str | None:\n",
    "    try:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        return \"\\n\".join(page.extract_text() for page in pdf_reader.pages)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Process a single Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "from ragatouille.data import CorpusProcessor\n",
    "\n",
    "\n",
    "def process_document(\n",
    "    document_file,\n",
    "    document_data,\n",
    "    model,\n",
    "):\n",
    "    logger.info(\"Setting up RAG\")\n",
    "    RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "    corpus_processor = CorpusProcessor()\n",
    "    documents = corpus_processor.process_corpus([load_pdf(document_file)])\n",
    "    RAG.encode([x['content'] for x in documents])\n",
    "\n",
    "    logger.info(\"Predicting\")\n",
    "    answers = {}\n",
    "    sections = {}\n",
    "    for index, row in document_data.iterrows():\n",
    "        question = row[\"question\"]\n",
    "\n",
    "        logger.info(f\"Question: {question}\")\n",
    "        logger.info(\"RAG search\")\n",
    "        results = RAG.search_encoded_docs(query=question, k=3)\n",
    "        logger.info(\"RESULTS\")\n",
    "        logger.info(results)\n",
    "        current_info = \"\\n\".join(result[\"content\"] for result in results)\n",
    "        logger.info(current_info)\n",
    "\n",
    "        answer = model.model.generate_content([f\"This is the document: {current_info}\"], question)\n",
    "        logger.info(answer)\n",
    "        answers[index] = answer\n",
    "        sections[index] = None\n",
    "\n",
    "    return answers, sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from structured_qa.model_loaders import load_gemini_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are given an input document and a question.\n",
    "You can only answer the question based on the information in the document.\n",
    "You will return a JSON name with two keys: \"section\" and \"answer\".\n",
    "In `\"section\"`, you will return the name of the section where you found the answer.\n",
    "In `\"answer\"`, you will return the answer one of the following JSON:\n",
    "- Yes/No (for boolean questions)\n",
    "Is the model an LLM?\n",
    "{\n",
    "  \"section\": \"1. Introduction\",\n",
    "  \"answer\": \"No\"\n",
    "}\n",
    "- Single number (for numeric questions)\n",
    "How many layers does the model have?\n",
    "{\n",
    "  \"section\": \"2. Architecture\",\n",
    "  \"answer\": 12\n",
    "}\n",
    "- Single letter (for multiple-choice questions)\n",
    "What is the activation function used in the model?\n",
    "-A: ReLU\n",
    "-B: Sigmoid\n",
    "-C: Tanh\n",
    "{\n",
    "  \"section\": \"2. Architecture\",\n",
    "  \"answer\": \"C\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_gemini_model(\n",
    "    \"gemini-2.0-flash-exp\",\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    generation_config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "logger.info(\"Loading input data\")\n",
    "data = pd.read_csv(\"structured_qa.csv\")\n",
    "data[\"pred_answer\"] = [None] * len(data)\n",
    "data[\"pred_section\"] = [None] * len(data)\n",
    "\n",
    "for document_link, document_data in data.groupby(\"document\"):\n",
    "    logger.info(f\"Downloading document {document_link}\")\n",
    "    downloaded_document = Path(f\"{Path(document_link).name}.pdf\")\n",
    "    if not Path(downloaded_document).exists():\n",
    "        urlretrieve(document_link, downloaded_document)\n",
    "        logger.info(f\"Downloaded {document_link} to {downloaded_document}\")\n",
    "    else:\n",
    "        logger.info(f\"File {downloaded_document} already exists\")\n",
    "\n",
    "    answers, sections = process_document(downloaded_document, document_data, model)\n",
    "\n",
    "    for index in document_data.index:\n",
    "        data.loc[index, \"pred_answer\"] = str(answers[index]).upper()\n",
    "        data.loc[index, \"pred_section\"] = sections[index]\n",
    "\n",
    "data.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results.csv\")\n",
    "results.loc[results[\"answer\"] != results[\"pred_answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(results[\"answer\"] == results[\"pred_answer\"]) / len(results)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
